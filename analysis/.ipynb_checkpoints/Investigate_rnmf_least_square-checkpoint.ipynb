{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "* I want to see how well `randomized nmf` performs. It is from  https://github.com/erichson/ristretto (the paper is https://arxiv.org/abs/1711.02037)\n",
    "\n",
    "* For now it can only solve least squares problem (`forbenius norm`, normal model). But it is still interesting to see if it can really fasten the computation, get good least square loss. \n",
    "\n",
    "\n",
    "## Algorithm used in comparison\n",
    "\n",
    "* `NMF with HALS` solves non-negative least squares problem with HALS (Hierarchical alternating least squares algorithm). Code is https://github.com/erichson/ristretto/blob/master/ristretto/nmf.py\n",
    "\n",
    "* `Randomized NMF with HALS` projects original data matrix `X` into a smaller dimensional space, then solves non-negative least squares problem with HALS (Hierarchical alternating least squares algorithm)\n",
    "https://github.com/erichson/ristretto/blob/master/ristretto/nmf.py\n",
    "\n",
    "* `skd.nmf` solves using either `mu` or `cd` update with `cd` being faster. Documentation is https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html\n",
    " \n",
    "* Note: the default `tol` is `1e-04` for `NMF HALS` and `1e-05` for `Randomized NMF HALS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "* I simulate data (`p` = 5000, `n` = 1000) from a normal model, then compute the average least square error of the fit.\n",
    "\n",
    "* For each method, I tried deterministic initialization: `nndsvd` and `nndsvda` (the second one taking 0s to be average of the other elements)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "\n",
    "The results are obtained from one experiment, so are tentative.\n",
    "\n",
    "* all those methods can beat oracle if initializaed properly\n",
    "\n",
    "* Initialization is quite important for those methods (and they seem to prefer different initialization methods), and there seems to be \"tradeoff\" between speed and loss. I think it is only because starting at a bad spot leads to early stopping at a bad critical point.\n",
    "\n",
    "* If we only consider result that beats oracle, then the computation time (in seconds) is: \n",
    "```txt\n",
    "0.319 (randomized nmf hals; init =  nndsvd) \n",
    "1.608 (skdnmf cd; init = random)\n",
    "2.117 (nmf hals; init = nndsvda)\n",
    "2.739 (skdnmf cd; init =  nndsvd)\n",
    "```\n",
    "\n",
    "#### See code below for the comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(0,'../code/')\n",
    "from utility import compute_loglik\n",
    "import ristretto\n",
    "from ristretto.nmf import compute_nmf\n",
    "from ristretto.nmf import compute_rnmf\n",
    "from scipy.stats import poisson\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_least_sqr_loss(X,Lam):\n",
    "    p, n = X.shape\n",
    "    return (np.square((X - Lam))).sum()/(n*p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_normal(n, p, rank, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    W = np.random.normal(loc = 1, size=(rank, n))\n",
    "    W = np.exp(W)\n",
    "    A = np.random.normal(loc = 1, size=(p, rank))\n",
    "    A = np.exp(A)\n",
    "    Lam = A.dot(W)\n",
    "    X = np.random.normal(loc=Lam, scale = 1, size = (p,n)) \n",
    "    X[np.where(X < 0 )] = 0\n",
    "    ll = compute_least_sqr_loss(X,Lam)\n",
    "    return X, Lam, ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean least square ll: 0.9993854013831657\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "p = 5000\n",
    "r = 5\n",
    "np.random.seed(123)\n",
    "X, Lam,ll = simulate_normal(n,p,r)\n",
    "ls_ll = compute_least_sqr_loss(X,Lam)\n",
    "print(\"mean least square ll: \" + str(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: p 5000 n  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape: p \" + str(X.shape[0]) + \" n \", str(X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF with HALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init = 'nndsvd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 10.211270093917847\n",
      "mean least square ll: 0.9935328734741082\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "A,W = compute_nmf(X,rank=r,init = 'nndsvd', tol=1e-05, maxiter= 10000)\n",
    "runtime = time.time() - start\n",
    "print(\"runtime: \" + str(runtime))\n",
    "ls_ll = compute_least_sqr_loss(X,A.dot(W))\n",
    "print(\"mean least square ll: \" + str(ls_ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init = 'nndsvda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 0.5625598430633545\n",
      "mean least square ll: 1.1221327205708158\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "A,W = compute_nmf(X,rank=r,init = 'nndsvda', tol=1e-05, maxiter= 10000)\n",
    "runtime = time.time() - start\n",
    "print(\"runtime: \" + str(runtime))\n",
    "ls_ll = compute_least_sqr_loss(X,A.dot(W))\n",
    "print(\"mean least square ll: \" + str(ls_ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized NMF with HALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init = 'nndsvd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 1.0360560417175293\n",
      "mean least square ll: 0.9935328737950804\n",
      "min element of X:  0.6831562022970761\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "A,W = compute_rnmf(X,rank=r, oversample=20,init = 'nndsvd',random_state = 0,tol=1e-05, maxiter= 10000)\n",
    "runtime = time.time() - start\n",
    "print(\"runtime: \" + str(runtime))\n",
    "ls_ll = compute_least_sqr_loss(X,A.dot(W))\n",
    "print(\"mean least square ll: \" + str(ls_ll))\n",
    "print(\"min element of X: \", X.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init = 'nndsvda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 0.21465015411376953\n",
      "mean least square ll: 1.1222547243541725\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "A,W = compute_rnmf(X,rank=r, oversample=20,init = 'nndsvda',random_state = 0,tol=1e-05, maxiter= 10000)\n",
    "runtime = time.time() - start\n",
    "print(\"runtime: \" + str(runtime))\n",
    "ls_ll = compute_least_sqr_loss(X,A.dot(W))\n",
    "print(\"mean least square ll: \" + str(ls_ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to improve loss by more oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 0.23541998863220215\n",
      "mean least square ll: 1.1222627378064045\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "A,W = compute_rnmf(X,rank=r, oversample=30,init = 'nndsvda',random_state = 0,tol=1e-05, maxiter= 10000)\n",
    "runtime = time.time() - start\n",
    "print(\"runtime: \" + str(runtime))\n",
    "ls_ll = compute_least_sqr_loss(X,A.dot(W))\n",
    "print(\"mean least square ll: \" + str(ls_ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skdNMF `cd` solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init=\"nndsvd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 10.500746011734009\n",
      "mean least square ll: 0.9935330769531381\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#print(\"fit\")\n",
    "model = NMF(n_components=r, init=\"nndsvd\", tol = 1e-05, beta_loss='frobenius',solver = \"cd\",\n",
    "                random_state=0, max_iter = 10000, verbose = False)\n",
    "model.fit(X.T)\n",
    "#print(\"transform\")\n",
    "L = model.transform(X.T)\n",
    "runtime = runtime = time.time() - start\n",
    "print(\"runtime: \" + str(runtime))\n",
    "F = model.components_ \n",
    "A = F.T\n",
    "W = L.T\n",
    "ls_ll = compute_least_sqr_loss(X,A.dot(W))\n",
    "print(\"mean least square ll: \" + str(ls_ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init = \"nndsvda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 0.6448521614074707\n",
      "mean least square ll: 1.1168937849426908\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#print(\"fit\")\n",
    "model = NMF(n_components=r, init=\"nndsvda\", tol = 1e-05, beta_loss='frobenius',solver = \"cd\",\n",
    "                random_state=0, max_iter = 10000, verbose = False)\n",
    "model.fit(X.T)\n",
    "#print(\"transform\")\n",
    "L = model.transform(X.T)\n",
    "runtime = runtime = time.time() - start\n",
    "print(\"runtime: \" + str(runtime))\n",
    "F = model.components_ \n",
    "A = F.T\n",
    "W = L.T\n",
    "ls_ll = compute_least_sqr_loss(X,A.dot(W))\n",
    "print(\"mean least square ll: \" + str(ls_ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init = \"random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 24.33019208908081\n",
      "mean least square ll: 0.9935238094626783\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#print(\"fit\")\n",
    "model = NMF(n_components=r, init=\"random\", tol = 1e-06, beta_loss='frobenius',solver = \"cd\",\n",
    "                random_state=0, max_iter = 10000, verbose = False)\n",
    "model.fit(X.T)\n",
    "#print(\"transform\")\n",
    "L = model.transform(X.T)\n",
    "runtime = runtime = time.time() - start\n",
    "print(\"runtime: \" + str(runtime))\n",
    "F = model.components_ \n",
    "A = F.T\n",
    "W = L.T\n",
    "ls_ll = compute_least_sqr_loss(X,A.dot(W))\n",
    "print(\"mean least square ll: \" + str(ls_ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#print(\"fit\")\n",
    "model = NMF(n_components=r, init=\"random\", tol = 5*1e-05, beta_loss='frobenius',solver = \"cd\",\n",
    "                random_state=0, max_iter = 10000, verbose = False)\n",
    "model.fit(X.T)\n",
    "#print(\"transform\")\n",
    "L = model.transform(X.T)\n",
    "runtime = runtime = time.time() - start\n",
    "print(\"runtime: \" + str(runtime))\n",
    "F = model.components_ \n",
    "A = F.T\n",
    "W = L.T\n",
    "ls_ll = compute_least_sqr_loss(X,A.dot(W))\n",
    "print(\"mean least square ll: \" + str(ls_ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
